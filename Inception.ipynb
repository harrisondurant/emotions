{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapted from [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "#### Import TensorFlow and inception model helper file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import prettytensor as pt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.misc import imread\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Functions and classes for loading and using the Inception model.\n",
    "import _inception as inception\n",
    "import _dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the model if necessary, and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inception.data_dir = 'inception_data/'\n",
    "inception.maybe_download()\n",
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.BuPu):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset using ```dataset.py``` helper file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = ds.load_cached(cache_path='tilburg.pkl', in_dir='data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get absolute filepaths for each image in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filepaths(in_dir, filenames):\n",
    "    filepaths = []\n",
    "    for name in filenames:\n",
    "        filepaths.extend(os.path.join(in_dir, name))\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cache_path = os.path.join('data/','tilburg.pkl')\n",
    "image_paths, cls, labels = dataset.get_training_set()\n",
    "transfer_values = inception.transfer_values_cache(cache_path, model, \\\n",
    "                                                  image_paths=image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(num_images, batch_size=64):\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split(dataset, idx, data, labels, num_actors=50):\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i,k in enumerate(dataset.filenames):\n",
    "        added = False\n",
    "        for x in idx:\n",
    "            if k == str(x) + '.jpg' or k == str(x) + '(flipped).jpg':\n",
    "                test_idx.append(i)\n",
    "                added = True\n",
    "        \n",
    "        if not added:\n",
    "            train_idx.append(i)\n",
    "    \n",
    "    X_train = data[train_idx,:]\n",
    "    X_train_labels = labels[train_idx,:]\n",
    "    X_test = data[test_idx,:]\n",
    "    X_test_labels = labels[test_idx,:]\n",
    "    return (X_train, X_train_labels, X_test, X_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize all placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, dim = transfer_values.shape\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# create placeholders for transfer values and labels\n",
    "x = tf.placeholder(tf.float32, shape=[None, dim], name='x')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# wrap the transfer-values as a Pretty Tensor object.\n",
    "x_pretty = pt.wrap(x)\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        fully_connected(size=1024, name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes, labels=y_true)\n",
    "\n",
    "# create optimizer and global step variable for training\n",
    "global_step = tf.Variable(initial_value=0, \\\n",
    "                           name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss, global_step)\n",
    "\n",
    "# create placeholders for predictions and accuracy\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(num_iters, check_every=100):\n",
    "    \n",
    "    thresh = 1e-6\n",
    "    prev = 0.0\n",
    "    \n",
    "    best = 0.0\n",
    "    best_pred = np.zeros_like(y_batch)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        feed_dict = {x: x_batch, y_true: y_batch}\n",
    "\n",
    "        # global iteration counter\n",
    "        i_global, _ = session.run([global_step, optimizer],\n",
    "                                  feed_dict=feed_dict)\n",
    "        \n",
    "        # Calculate the accuracy on the test set.\n",
    "        feed_dict_test = {x: X_test, y_true: X_test_labels}\n",
    "        test_acc = session.run(accuracy,\n",
    "                                feed_dict=feed_dict_test)\n",
    "        \n",
    "        if test_acc > best:\n",
    "            best = test_acc\n",
    "            best_pred = session.run(y_pred_cls,\n",
    "                                feed_dict=feed_dict_test)\n",
    "        \n",
    "        # Print status to screen every 100 iterations (and last).\n",
    "        if (i % check_every == 0) or (i == num_iters-1):\n",
    "            \n",
    "            if (i == num_iters-1):\n",
    "                # Print status.\n",
    "                msg = '-- Step: {}, Best Test-Set Accuracy: {:.2f}'\n",
    "                print(msg.format(i+1,btest))\n",
    "                return best, best_pred\n",
    "            \n",
    "            # if no significant change in accuracy\n",
    "            if abs(test_acc - prev) <= thresh:\n",
    "                msg = '-- Diverging after {} steps. ' + \\\n",
    "                      'Best Test-Set Accuracy: {:.2f}'\n",
    "                print(msg.format(i, best))\n",
    "                return best, best_pred\n",
    "            \n",
    "            prev = test_acc\n",
    "        \n",
    "    return best, best_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a single training/test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Get a random train/test split of the dataset\n",
    "fold_idx = random_batch(50, batch_size=5)\n",
    "x_batch, y_batch, X_test, X_test_labels = split(dataset, \\\n",
    "                                                fold_idx, \\\n",
    "                                                transfer_values, \\\n",
    "                                                labels)\n",
    "# Train for a set number of iterations\n",
    "num_iters = 500\n",
    "print('Optimizing...')\n",
    "_, pred = optimize(num_iters, check_every=25)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=pred, y_true=np.argmax(X_test_labels, axis=1))\n",
    "plot_confusion_matrix(cm, dataset.class_names)\n",
    "\n",
    "# Close session and Inception model\n",
    "session.close()\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 10-fold cross validation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep running average confusion matrix, accuracy variables\n",
    "cm_avg = np.zeros((dataset.num_classes, dataset.num_classes))\n",
    "acc_sum = 0.0\n",
    "\n",
    "num_folds = 10\n",
    "num_iters = 400\n",
    "num_actors = 50\n",
    "\n",
    "# create KFold object to split data evenly among each fold\n",
    "kf = KFold(num_actors, num_folds, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "for i, idx in enumerate(kf):\n",
    "    \n",
    "    # Initialize the session\n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # get train/test split\n",
    "    x_batch, y_batch, X_test, X_test_labels = split(dataset, \\\n",
    "                                                    idx[1], \\\n",
    "                                                    transfer_values, \\\n",
    "                                                    labels)\n",
    "    \n",
    "    # train for set number of iterations or until divergence\n",
    "    print('Optimizing: fold {} of {}'.format(i+1, num_folds))\n",
    "    acc, pred = optimize(num_iters, check_every=25)\n",
    "    \n",
    "    # accumulate confusion matrix and accuracy values\n",
    "    cm_avg += confusion_matrix(y_pred=pred, \\\n",
    "                               y_true=np.argmax(X_test_labels, axis=1))\n",
    "    acc_sum += acc\n",
    "\n",
    "    # close the session\n",
    "    session.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    \n",
    "# compute mean accuracy over all folds\n",
    "overall_acc = acc_sum / num_folds\n",
    "print('Mean Test-Set Accuracy After {}-fold Cross Validation: {:.2f}' \\\n",
    "     .format(num_folds, overall_acc))\n",
    "\n",
    "# compute mean confusion matrix over all folds\n",
    "cm_avg /= num_folds\n",
    "plot_confusion_matrix(cm_avg, dataset.class_names, \\\n",
    "                      title='Mean Confusion Matrix')\n",
    "\n",
    "# close the Inception model\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
